{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neversettlejay/mineai_cote_gold/blob/no_validation/MineAI_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR42mOT4riKV"
      },
      "source": [
        "# MineAI - Optimizing Open-Pit Blast Performance with Machine Learning\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project focuses on using algorithms and available data to rate the effectiveness of open pit blasts. The goal is to suggest optimal parameters that can improve drill and blast efficiency, as well as reduce the deviation between planned and actual drilling results (e.g., drill hole deviations, blast outcomes, etc.). Through data analysis and predictive modeling, the project aims to enhance mining operations by optimizing blast designs, improving fragmentation, and reducing unplanned costs due to inefficiencies in drilling and blasting.\n",
        "\n",
        "\n",
        "## Team Members\n",
        "\n",
        "* Manav Chaudhary - Mining Engineer\n",
        "* Shrey Patel - Machine Learning Engineer\n",
        "* Soham Salakhana - Mining Engineer\n",
        "* Shakil Kalvatar - Mining Engineer\n",
        "* Jay Rathod - Software Engineer\n",
        "\n",
        "\n",
        "## Data and Methodology\n",
        "\n",
        "This project will leverage:\n",
        "\n",
        "* Historical data from past drill and blast operations\n",
        "* Sensor data from the mine, including real-time measurements of blast outcomes and drill hole characteristics\n",
        "* Statistical methods, machine learning algorithms, and optimization techniques to rate blast performance\n",
        "* Suggestions for optimizing parameters like drill depth, spacing, and blast charge amounts\n",
        "\n",
        "\n",
        "## Key Objectives\n",
        "\n",
        "* Rate the success of each blast based on fragmentation size, efficiency, and deviation from the planned design.\n",
        "* Use machine learning algorithms to identify patterns in the data and suggest improvements to drill and blast parameters.\n",
        "* Propose changes to the drilling process to reduce deviation and optimize efficiency, ultimately improving cost and time savings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ48s_oLsKGh"
      },
      "source": [
        "# Installing Dependencies\n",
        "\n",
        "This section outlines the necessary steps to install the required dependencies for this project.\n",
        "\n",
        "We will be using the following libraries:\n",
        "\n",
        "* **pdf2image:**  Converts PDF files to images for analysis.\n",
        "* **imagehash:**  Generates perceptual hashes of images for comparison and similarity detection.\n",
        "* **poppler-utils:** Provides utilities for working with PDF files, including rendering and conversion.\n",
        "* **opencv-python:**  Open Source Computer Vision Library for image and video processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd64Olfd4nk0",
        "outputId": "de577840-532e-4cea-f68c-a2a9b087e04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 179, in _eval_op\n",
            "    spec = Specifier(\"\".join([op.serialize(), rhs]))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/specifiers.py\", line 237, in __init__\n",
            "    raise InvalidSpecifier(f\"Invalid specifier: '{spec}'\")\n",
            "pip._vendor.packaging.specifiers.InvalidSpecifier: Invalid specifier: '==dev'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in _compute_dependencies\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in <listcomp>\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3086, in reqs_for_extra\n",
            "    if not req.marker or req.marker.evaluate({'extra': extra}):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 325, in evaluate\n",
            "    return _evaluate_markers(self._markers, current_environment)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 225, in _evaluate_markers\n",
            "    groups[-1].append(_eval_op(lhs_value, op, rhs_value))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 179, in _eval_op\n",
            "    spec = Specifier(\"\".join([op.serialize(), rhs]))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1685, in print\n",
            "    render_options = self.options.update(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 983, in options\n",
            "    max_height=self.size.height,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1003, in size\n",
            "    if self.is_dumb_terminal:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 977, in is_dumb_terminal\n",
            "    return self.is_terminal and is_dumb\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 931, in is_terminal\n",
            "    @property\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "^C\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies\n",
        "\n",
        "!pip install pdf2image\n",
        "!pip install imagehash\n",
        "!apt-get install -y poppler-utils\n",
        "# !pip uninstall -y opencv-python opencv-python-headless\n",
        "!nvidia-smi\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMyh8BjOL60c"
      },
      "outputs": [],
      "source": [
        "# To use GPU\n",
        "# Remove any existing OpenCV installations\n",
        "# !pip uninstall -y opencv-python opencv-python-headless\n",
        "\n",
        "# # Install dependencies\n",
        "# !apt-get update && apt-get install -y \\\n",
        "#     build-essential cmake git unzip pkg-config \\\n",
        "#     libjpeg-dev libpng-dev libtiff-dev \\\n",
        "#     libavcodec-dev libavformat-dev libswscale-dev \\\n",
        "#     libv4l-dev libxvidcore-dev libx264-dev \\\n",
        "#     libgtk-3-dev libcanberra-gtk* \\\n",
        "#     libatlas-base-dev gfortran python3-dev \\\n",
        "#     libdc1394-22-dev libopenexr-dev libgstreamer-plugins-base1.0-dev \\\n",
        "#     libgstreamer1.0-dev libgphoto2-dev libeigen3-dev\n",
        "\n",
        "# # Clone OpenCV repositories\n",
        "# !git clone https://github.com/opencv/opencv.git\n",
        "# !git clone https://github.com/opencv/opencv_contrib.git\n",
        "\n",
        "# # Create a build directory\n",
        "# !mkdir -p opencv/build\n",
        "# %cd opencv/build\n",
        "\n",
        "# # Configure the build with CUDA support\n",
        "# !cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
        "#        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
        "#        -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \\\n",
        "#        -D WITH_CUDA=ON \\\n",
        "#        -D ENABLE_FAST_MATH=ON \\\n",
        "#        -D CUDA_FAST_MATH=ON \\\n",
        "#        -D WITH_CUDNN=ON \\\n",
        "#        -D OPENCV_DNN_CUDA=ON \\\n",
        "#        -D BUILD_opencv_python3=ON ..\n",
        "\n",
        "# # Build OpenCV (this might take a while)\n",
        "# !make -j$(nproc)\n",
        "\n",
        "# # Install the newly built OpenCV\n",
        "# !make install\n",
        "# !ldconfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fODMbgqyyAaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31d0b46-0445-4277-c8a3-1c9d8649fae0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# TO check whether GPU can be used\n",
        "import cv2\n",
        "print(cv2.cuda.getCudaEnabledDeviceCount())  # Should print a positive integer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNCj1g_wmzLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ce94d0-00eb-4728-b7e2-2c4fd14b7862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "\n",
        "#importing the given data from google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the file in Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SKYkNe10zGbG"
      },
      "outputs": [],
      "source": [
        "#extract images from pdf\n",
        "import os\n",
        "import shutil\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "from pdf2image import convert_from_path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base directory path in Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "\n",
        "# Define the main directories\n",
        "main_folders = [\"data\"]\n",
        "\n",
        "# --- CREATE CORRECT STRUCTURE AND EXTRACT IMAGES ---\n",
        "for main_folder in main_folders:\n",
        "    main_folder_path = os.path.join(parent_directory_path, main_folder)\n",
        "\n",
        "    for subfolder in os.listdir(main_folder_path):\n",
        "        subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Create a 'report' folder if it doesn't exist\n",
        "            report_folder = os.path.join(subfolder_path, 'report')\n",
        "            os.makedirs(report_folder, exist_ok=True)\n",
        "\n",
        "            # Find all PDF files in the subfolder\n",
        "            pdf_files = [f for f in os.listdir(subfolder_path) if f.endswith('.pdf')]\n",
        "\n",
        "            for pdf_file in pdf_files:\n",
        "                pdf_path = os.path.join(subfolder_path, pdf_file)\n",
        "\n",
        "                # Create a subfolder inside 'report' based on the PDF name\n",
        "                pdf_name = os.path.splitext(pdf_file)[0]\n",
        "                pdf_report_folder = os.path.join(report_folder, pdf_name)\n",
        "                os.makedirs(pdf_report_folder, exist_ok=True)\n",
        "\n",
        "                # Convert PDF to images\n",
        "                try:\n",
        "                    images = convert_from_path(pdf_path)\n",
        "                    for i, image in enumerate(images):\n",
        "                        image_path = os.path.join(pdf_report_folder, f'image_{i + 1}.jpg')\n",
        "                        image.save(image_path, 'JPEG')\n",
        "\n",
        "                    print(f\"Extracted images from {pdf_file} saved in {pdf_report_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {pdf_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEqMbQmKKZor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130f8030-796b-41ed-b3a7-021cf19362d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/328_109\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/340_102\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_103\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_108\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_121\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/364_303\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_312\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_138\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_137\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_132\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_131\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/364_105\n"
          ]
        }
      ],
      "source": [
        "#to list directories\n",
        "import os\n",
        "\n",
        "# Assuming you've already mounted your Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "data_folder = os.path.join(parent_directory_path, 'data')\n",
        "\n",
        "# List subdirectories\n",
        "for subdirectory in os.listdir(data_folder):\n",
        "    subdirectory_path = os.path.join(data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        print(subdirectory_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvyNm4wSH3D7"
      },
      "outputs": [],
      "source": [
        "#crop video (moving object)\n",
        "import os\n",
        "import logging\n",
        "import cv2\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')\n",
        "output_folder = os.path.join(parent_directory_path, 'processed_videos')\n",
        "\n",
        "# Subfolders to process\n",
        "subfolders = ['C1_328_109', 'C1_340_102', 'C1_352_103', 'C1_352_108', 'C1_352_137', 'C1_352_132',\n",
        "              'C1_352_131', 'C1_352_121', 'C1_364_303', 'C1_364_105', 'C1_352_312', 'C1_352_138']\n",
        "\n",
        "# Supported video extensions\n",
        "video_extensions = ['.mp4', '.MP4', '.avi', '.AVI', '.mov', '.MOV', '.mkv', '.MKV']\n",
        "\n",
        "# Ensure output directory structure exists\n",
        "for subfolder in subfolders:\n",
        "    os.makedirs(os.path.join(output_folder, subfolder), exist_ok=True)\n",
        "\n",
        "# Initialize YOLOv8 model\n",
        "model = YOLO(\"yolov8s.pt\")  # Load the pretrained model\n",
        "\n",
        "# Define helper functions\n",
        "def box_center(coords):\n",
        "    left, top, right, bottom = coords\n",
        "    return [(left + right) / 2, (top + bottom) / 2]\n",
        "\n",
        "def adjust_box_size(coords, box_width, box_height):\n",
        "    center_x, center_y = box_center(coords)\n",
        "    return [\n",
        "        center_x - box_width / 2, center_y - box_height / 2,\n",
        "        center_x + box_width / 2, center_y + box_height / 2\n",
        "    ]\n",
        "\n",
        "def adjust_boundaries(coords, screen):\n",
        "    left, top, right, bottom = coords\n",
        "    width, height = screen\n",
        "    if left < 0:\n",
        "        right -= left\n",
        "        left = 0\n",
        "    if top < 0:\n",
        "        bottom -= top\n",
        "        top = 0\n",
        "    if right > width:\n",
        "        left -= (right - width)\n",
        "        right = width\n",
        "    if bottom > height:\n",
        "        top -= (bottom - height)\n",
        "        bottom = height\n",
        "    return [round(left), round(top), round(right), round(bottom)]\n",
        "\n",
        "def check_video_empty(vid_capture):\n",
        "    \"\"\"Check if a video is empty or corrupt.\"\"\"\n",
        "    if vid_capture.isOpened() == False:\n",
        "        return True\n",
        "    ret, frame = vid_capture.read()\n",
        "    if not ret or frame is None:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_steady_frame(frame, last_frame, threshold=5):\n",
        "    \"\"\"Check if the current frame is steady (no significant changes).\"\"\"\n",
        "    if last_frame is None:\n",
        "        return False\n",
        "    # Compute the difference between the current and the previous frame\n",
        "    diff = cv2.absdiff(frame, last_frame)\n",
        "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "    non_zero_count = cv2.countNonZero(diff_gray)\n",
        "    if non_zero_count < threshold:\n",
        "        return True  # Steady frame\n",
        "    return False\n",
        "\n",
        "# Process videos\n",
        "for subfolder in subfolders:\n",
        "    input_path = os.path.join(video_folder, subfolder)\n",
        "    output_path = os.path.join(output_folder, subfolder)\n",
        "\n",
        "    for file_name in os.listdir(input_path):\n",
        "        if os.path.splitext(file_name)[1] in video_extensions:\n",
        "            input_video = os.path.join(input_path, file_name)\n",
        "            output_video = os.path.join(output_path, f\"processed_{subfolder}.mp4\")\n",
        "\n",
        "            logger.info(f\"Processing video: {input_video}\")\n",
        "\n",
        "            # Open input video\n",
        "            vid_capture = cv2.VideoCapture(input_video)\n",
        "            fps = int(vid_capture.get(cv2.CAP_PROP_FPS))\n",
        "            width = int(vid_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(vid_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "            # Check if the video is empty or corrupt\n",
        "            if check_video_empty(vid_capture):\n",
        "                logger.warning(f\"Skipping empty or corrupt video: {input_video}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize cropping box\n",
        "            box_width, box_height = 500, 500\n",
        "            default_coords = [100, 100, 600, 600]  # Default box\n",
        "            last_box_coords = default_coords\n",
        "            last_frame = None\n",
        "\n",
        "            # Open output video stream\n",
        "            output_writer = cv2.VideoWriter(\n",
        "                output_video,\n",
        "                cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                fps,\n",
        "                (box_width, box_height)\n",
        "            )\n",
        "\n",
        "            # Process video frames\n",
        "            frame_counter = 0\n",
        "            steady_frame_counter = 0  # To track how many steady frames\n",
        "            min_frames = 5 * fps  # Ensure the video is at least 5 seconds long\n",
        "            while True:\n",
        "                ret, frame = vid_capture.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Check if the frame is steady\n",
        "                if is_steady_frame(frame, last_frame):\n",
        "                    steady_frame_counter += 1\n",
        "                else:\n",
        "                    steady_frame_counter = 0  # Reset if motion is detected\n",
        "\n",
        "                # YOLO detection\n",
        "                results = model.predict(source=frame, conf=0.5, iou=0.1)\n",
        "                boxes = results[0].boxes\n",
        "\n",
        "                if boxes:\n",
        "                    # Use the first detected box\n",
        "                    box = boxes[0].xyxy[0].cpu().numpy().astype(int)\n",
        "                    last_box_coords = adjust_box_size(box, box_width, box_height)\n",
        "                    last_box_coords = adjust_boundaries(last_box_coords, [width, height])\n",
        "\n",
        "                # Use the last known cropping box\n",
        "                box_left, box_top, box_right, box_bottom = last_box_coords\n",
        "\n",
        "                # Crop and write frame\n",
        "                cropped_frame = frame[box_top:box_bottom, box_left:box_right]\n",
        "                output_writer.write(cropped_frame)\n",
        "\n",
        "                # Update last frame for steady check\n",
        "                last_frame = frame\n",
        "\n",
        "                frame_counter += 1\n",
        "\n",
        "            # Ensure video has sufficient length\n",
        "            if frame_counter < min_frames:\n",
        "                logger.info(f\"Padding {min_frames - frame_counter} frames to video {output_video}\")\n",
        "                padding_frame = cropped_frame.copy()\n",
        "                for _ in range(min_frames - frame_counter):\n",
        "                    output_writer.write(padding_frame)\n",
        "\n",
        "            # Log if there were many steady frames\n",
        "            if steady_frame_counter > 50:\n",
        "                logger.info(f\"Detected {steady_frame_counter} steady frames in {input_video}\")\n",
        "\n",
        "            # Release resources\n",
        "            vid_capture.release()\n",
        "            output_writer.release()\n",
        "            logger.info(f\"Saved processed video to {output_video}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PQFsMbvhFLy1"
      },
      "outputs": [],
      "source": [
        "#extract frames from video every 300 ms\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')  # Path to the \"data\" folder\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(extracted_frames_dir, exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'frame_extraction.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Common video file extensions\n",
        "video_extensions = ['.mp4', '.MP4', '.avi', '.AVI', '.mov', '.MOV', '.mkv', '.MKV']\n",
        "\n",
        "def extract_frames(video_path, output_dir, frame_step=10):\n",
        "    \"\"\"\n",
        "    Extract frames from a video and save them based on timestamps in milliseconds.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        output_dir (str): Directory to save the frames.\n",
        "        frame_step (int): Interval to save frames (e.g., every nth frame).\n",
        "    \"\"\"\n",
        "    video_name = os.path.basename(video_path).split('.')[0]\n",
        "    video_frames_dir = os.path.join(output_dir, video_name)\n",
        "    os.makedirs(video_frames_dir, exist_ok=True)  # Create a subdirectory for the video\n",
        "\n",
        "    logging.info(f\"Processing video: {video_name}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        logging.error(f\"Failed to open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frame rate\n",
        "    frame_count = 0\n",
        "    saved_frames = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            logging.info(f\"End of video reached: {video_path}\")\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % frame_step != 0:\n",
        "            continue\n",
        "\n",
        "        # Get timestamp in milliseconds\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))  # Get timestamp in milliseconds\n",
        "\n",
        "        # Save frame with timestamp\n",
        "        frame_filename = os.path.join(video_frames_dir, f\"frame_{timestamp_ms:012d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        saved_frames += 1\n",
        "\n",
        "    cap.release()\n",
        "    logging.info(f\"Saved {saved_frames} frames from video: {video_name}\")\n",
        "\n",
        "def process_all_videos(video_folder, output_dir):\n",
        "    \"\"\"\n",
        "    Processes all videos in a folder and its subfolders, extracting frames.\n",
        "\n",
        "    Args:\n",
        "        video_folder (str): Directory containing all videos.\n",
        "        output_dir (str): Directory to save extracted frames.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for videos in folder: {video_folder}\")\n",
        "    files_found = False\n",
        "    for root, dirs, files in os.walk(video_folder):\n",
        "        for file in files:\n",
        "            if any(file.endswith(ext) for ext in video_extensions):\n",
        "                files_found = True\n",
        "                video_path = os.path.join(root, file)\n",
        "                logging.info(f\"Processing video: {file} in {root}\")\n",
        "                extract_frames(video_path, output_dir)\n",
        "\n",
        "    if not files_found:\n",
        "        logging.warning(f\"No video files found in {video_folder} or its subfolders.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting frame extraction process...\")\n",
        "    process_all_videos(video_folder, extracted_frames_dir)\n",
        "    logging.info(\"Frame extraction process completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_qG2XmYa8jr"
      },
      "outputs": [],
      "source": [
        "#conver to greyscale\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import logging\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'  # Replace with your actual path\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "extracted_frames_greyscale_dir = os.path.join(parent_directory_path, 'extracted_frames_greyscale')\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(extracted_frames_greyscale_dir, exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'greyscale_conversion.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def convert_to_greyscale(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Converts all images in a directory and its subfolders to greyscale using glob.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for images in folder: {input_dir}\")\n",
        "\n",
        "    # Use glob to find all image files (adjust the pattern if needed)\n",
        "    image_files = glob.glob(os.path.join(input_dir, '**', 'frame_*.jpg'), recursive=True)\n",
        "\n",
        "    for image_path in image_files:\n",
        "        try:\n",
        "            # Read the image\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                logging.warning(f\"Failed to read image: {image_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Convert to greyscale\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Construct the output path using string manipulation\n",
        "            relative_path = os.path.relpath(image_path, input_dir)\n",
        "            output_image_path = os.path.join(output_dir, relative_path)\n",
        "            output_dir_name = os.path.dirname(output_image_path)\n",
        "            os.makedirs(output_dir_name, exist_ok=True)  # Create output directory\n",
        "\n",
        "            # Save the greyscale image\n",
        "            cv2.imwrite(output_image_path, gray_img)\n",
        "            logging.info(f\"Converted {image_path} to greyscale and saved to {output_image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting greyscale conversion process...\")\n",
        "    convert_to_greyscale(extracted_frames_dir, extracted_frames_greyscale_dir)\n",
        "    logging.info(\"Greyscale conversion process completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CW_rYI-IDPc"
      },
      "outputs": [],
      "source": [
        "#lukas kanade method\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')  # Path to the \"data\" folder\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "lukas_kanade_dir = os.path.join(parent_directory_path, 'lukas_kanade')\n",
        "\n",
        "# Create Lukas Kanade subfolders\n",
        "subfolders = ['328_109', '340_102', '352_103', '352_108', '352_137', '352_132', '352_131', '352_121', '364_303', '364_105', '352_312', '352_138']\n",
        "for subfolder in subfolders:\n",
        "    os.makedirs(os.path.join(lukas_kanade_dir, subfolder), exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'lukas_kanade.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def compute_optical_flow(prev_gray, next_gray):\n",
        "    \"\"\"\n",
        "    Compute the optical flow between two consecutive frames using Lucas-Kanade method.\n",
        "\n",
        "    Args:\n",
        "        prev_gray (ndarray): Grayscale image of the previous frame.\n",
        "        next_gray (ndarray): Grayscale image of the current frame.\n",
        "\n",
        "    Returns:\n",
        "        flow (ndarray): Optical flow vectors.\n",
        "    \"\"\"\n",
        "    # Parameters for Lucas-Kanade optical flow\n",
        "    flow = cv2.calcOpticalFlowFarneback(\n",
        "        prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
        "    )\n",
        "    return flow\n",
        "\n",
        "def draw_optical_flow(flow, frame, filename):\n",
        "    \"\"\"\n",
        "    Draws the optical flow on the frame and saves the result.\n",
        "\n",
        "    Args:\n",
        "        flow (ndarray): Optical flow vectors.\n",
        "        frame (ndarray): Current frame.\n",
        "        filename (str): File name to save the frame with flow visualization.\n",
        "    \"\"\"\n",
        "    # Convert flow to polar coordinates\n",
        "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "    # Create an image to display the flow\n",
        "    hsv = np.zeros_like(frame)\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 0] = angle * 180 / np.pi / 2  # Hue represents direction\n",
        "    hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)  # Value represents magnitude\n",
        "\n",
        "    flow_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)  # Convert back to BGR for display\n",
        "\n",
        "    # Save the optical flow image\n",
        "    cv2.imwrite(filename, flow_bgr)\n",
        "\n",
        "def apply_lukas_kanade_to_frames(video_frames_dir, lukas_kanade_subfolder):\n",
        "    \"\"\"\n",
        "    Apply Lucas-Kanade optical flow to all extracted frames and save the flow visualization.\n",
        "\n",
        "    Args:\n",
        "        video_frames_dir (str): Directory containing extracted frames.\n",
        "        lukas_kanade_subfolder (str): Subfolder to save optical flow images.\n",
        "    \"\"\"\n",
        "    frames = sorted([f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')])\n",
        "    prev_frame = None\n",
        "    prev_gray = None\n",
        "\n",
        "    for i, frame_filename in enumerate(frames):\n",
        "        frame_path = os.path.join(video_frames_dir, frame_filename)\n",
        "        frame = cv2.imread(frame_path)\n",
        "\n",
        "        # Convert the frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if prev_frame is not None:\n",
        "            # Compute optical flow between previous and current frame\n",
        "            flow = compute_optical_flow(prev_gray, gray_frame)\n",
        "\n",
        "            # Create the filename for saving the optical flow visualization\n",
        "            flow_filename = os.path.join(lukas_kanade_subfolder, frame_filename)\n",
        "\n",
        "            # Draw and save optical flow\n",
        "            draw_optical_flow(flow, frame, flow_filename)\n",
        "\n",
        "        prev_frame = frame\n",
        "        prev_gray = gray_frame\n",
        "\n",
        "def process_all_videos_for_lukas_kanade(extracted_frames_dir, lukas_kanade_dir):\n",
        "    \"\"\"\n",
        "    Process all videos' extracted frames for optical flow and save the results.\n",
        "\n",
        "    Args:\n",
        "        extracted_frames_dir (str): Directory containing extracted frames.\n",
        "        lukas_kanade_dir (str): Directory to save optical flow images.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for extracted frames in folder: {extracted_frames_dir}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(extracted_frames_dir):\n",
        "        for subfolder in subfolders:\n",
        "            if subfolder in root:\n",
        "                lukas_kanade_subfolder = os.path.join(lukas_kanade_dir, subfolder)\n",
        "                video_frames_dir = root  # Current video frames folder\n",
        "                logging.info(f\"Processing frames in {video_frames_dir} for Lucas-Kanade optical flow.\")\n",
        "                apply_lukas_kanade_to_frames(video_frames_dir, lukas_kanade_subfolder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting Lucas-Kanade optical flow processing...\")\n",
        "    process_all_videos_for_lukas_kanade(extracted_frames_dir, lukas_kanade_dir)\n",
        "    logging.info(\"Lucas-Kanade optical flow processing completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssp-RBIsm3Xv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Input,\n",
        "    Concatenate,\n",
        "    GlobalAveragePooling2D,\n",
        "    Conv2D,\n",
        "    MaxPooling2D\n",
        ")\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_QQVJ4Km3Up"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "extracted_frames_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/extracted_frames\"\n",
        "output_csv = \"/content/drive/My Drive/pour_la_hackathon/MineAI/site_data.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Immwf8xoU8go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaf5ff8-9c8a-4d23-f16c-e4a7a4b56eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Site  Fragment Size Distribution  Visual Fragmentation  \\\n",
            "0   352_108                           1                     1   \n",
            "1   352_121                           3                     4   \n",
            "2   328_109                           4                     4   \n",
            "3   340_102                           3                     3   \n",
            "4   352_103                           3                     3   \n",
            "5   352_131                           4                     4   \n",
            "6   352_132                           1                     3   \n",
            "7   352_137                           4                     4   \n",
            "8   352_138                           2                     2   \n",
            "9   352_312                           3                     3   \n",
            "10  364_105                           3                     3   \n",
            "11  364_303                           3                     3   \n",
            "\n",
            "    Boulders (>1 m)  Fines (<10 mm)  Most Blasts  \\\n",
            "0                 1               3            2   \n",
            "1                 3               3            0   \n",
            "2                 4               3            0   \n",
            "3                 4               4            4   \n",
            "4                 3               2            0   \n",
            "5                 4               4            0   \n",
            "6                 1               4            0   \n",
            "7                 4               4            0   \n",
            "8                 0               0            0   \n",
            "9                 3               3            0   \n",
            "10                3               3            0   \n",
            "11                3               3            0   \n",
            "\n",
            "    For Development and Pinoeering blast  \\\n",
            "0                                      0   \n",
            "1                                      1   \n",
            "2                                      4   \n",
            "3                                      0   \n",
            "4                                      2   \n",
            "5                                      4   \n",
            "6                                      4   \n",
            "7                                      4   \n",
            "8                                      3   \n",
            "9                                      2   \n",
            "10                                     4   \n",
            "11                                     3   \n",
            "\n",
            "    Digability (Ease of Excavation) - Simple Method  Muckpile Height  \\\n",
            "0                                                 0                3   \n",
            "1                                                 0                4   \n",
            "2                                                 0                3   \n",
            "3                                                 0                3   \n",
            "4                                                 3                0   \n",
            "5                                                 3                0   \n",
            "6                                                 2                0   \n",
            "7                                                 4                0   \n",
            "8                                                 2                0   \n",
            "9                                                 4                0   \n",
            "10                                                4                0   \n",
            "11                                                3                0   \n",
            "\n",
            "    Swell Factor  ...  Muckpile Throw  Misfires/Blowouts  Swell and Spread  \\\n",
            "0              2  ...               1                  1                 3   \n",
            "1              4  ...               4                  2                 1   \n",
            "2              2  ...               3                  3                 2   \n",
            "3              4  ...               3                  2                 4   \n",
            "4              0  ...               1                  2                 2   \n",
            "5              0  ...               4                  4                 3   \n",
            "6              0  ...               4                  1                 2   \n",
            "7              0  ...               4                  3                 4   \n",
            "8              0  ...               3                  3                 2   \n",
            "9              0  ...               3                  3                 2   \n",
            "10             0  ...               3                  3                 3   \n",
            "11             0  ...               2                  2                 2   \n",
            "\n",
            "    Fragmentation Distribution.1  Muckpile Shape.1  Misfires/Blowouts.1  \\\n",
            "0                              1                 4                    1   \n",
            "1                              3                 1                    2   \n",
            "2                              4                 4                    3   \n",
            "3                              4                 4                    2   \n",
            "4                              3                 0                    2   \n",
            "5                              4                 3                    4   \n",
            "6                              1                 2                    1   \n",
            "7                              4                 4                    4   \n",
            "8                              2                 2                    3   \n",
            "9                              2                 2                    3   \n",
            "10                             4                 4                    3   \n",
            "11                             3                 4                    2   \n",
            "\n",
            "    Confinement and Ejection (Stemming Quality)  \\\n",
            "0                                             1   \n",
            "1                                             2   \n",
            "2                                             2   \n",
            "3                                             2   \n",
            "4                                             2   \n",
            "5                                             4   \n",
            "6                                             2   \n",
            "7                                             4   \n",
            "8                                             3   \n",
            "9                                             3   \n",
            "10                                            3   \n",
            "11                                            2   \n",
            "\n",
            "    (Vibration Monitor data available)Fish Spawning season - Yes  \\\n",
            "0                                                   0              \n",
            "1                                                   0              \n",
            "2                                                   0              \n",
            "3                                                   0              \n",
            "4                                                   0              \n",
            "5                                                   0              \n",
            "6                                                   0              \n",
            "7                                                   0              \n",
            "8                                                   0              \n",
            "9                                                   0              \n",
            "10                                                  0              \n",
            "11                                                  0              \n",
            "\n",
            "    (Vibration Monitor data available) Fish Spawning season - No  \\\n",
            "0                                                   0              \n",
            "1                                                   0              \n",
            "2                                                   0              \n",
            "3                                                   0              \n",
            "4                                                   0              \n",
            "5                                                   0              \n",
            "6                                                   0              \n",
            "7                                                   0              \n",
            "8                                                   0              \n",
            "9                                                   0              \n",
            "10                                                  0              \n",
            "11                                                  0              \n",
            "\n",
            "    Vibration Monitor Data not available  \n",
            "0                                      1  \n",
            "1                                      2  \n",
            "2                                      2  \n",
            "3                                      2  \n",
            "4                                      2  \n",
            "5                                      4  \n",
            "6                                      3  \n",
            "7                                      3  \n",
            "8                                      2  \n",
            "9                                      2  \n",
            "10                                     3  \n",
            "11                                     4  \n",
            "\n",
            "[12 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "# Subfolders (blast sites)\n",
        "subfolders = ['328_109', '340_102', '352_103', '352_108', '352_137',\n",
        "              '352_132', '352_131', '352_121', '364_303', '364_105',\n",
        "              '352_312', '352_138']\n",
        "\n",
        "# Load CSV data\n",
        "csv_data = pd.read_csv(output_csv)\n",
        "print(csv_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data and labels\n",
        "image_features = []\n",
        "labels = []\n",
        "\n",
        "# Image preprocessing parameters\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Read and preprocess a single image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_resized = cv2.resize(img, IMG_SIZE)  # Resize to IMG_SIZE\n",
        "    img_normalized = img_resized / 255.0  # Normalize pixel values\n",
        "    return img_normalized\n",
        "\n",
        "# Process each subfolder\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(extracted_frames_dir, subfolder)\n",
        "    # Check for corresponding data in the CSV\n",
        "    site_data = csv_data[csv_data[\"Site\"] == subfolder]\n",
        "    if site_data.empty:\n",
        "        print(f\"Warning: No CSV data found for {subfolder}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Get the label (parameter values) for this site\n",
        "    site_label = site_data.iloc[0, 1:].values.astype(np.float32)\n",
        "\n",
        "    # List all image files in the subfolder\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "        # Preprocess image\n",
        "        img_feature = preprocess_image(image_path)\n",
        "        image_features.append(img_feature)\n",
        "        labels.append(site_label)\n"
      ],
      "metadata": {
        "id": "P2qxQE9tmRVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLas1zgEm3Ir"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(image_features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcVXoS7Dm3F8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f437b93e-2bda-4c8f-e01b-e5128d4d76d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_train.shape[1], activation='linear')  # Output layer with the number of features\n",
        "])\n",
        "\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# # Image Size (adjust accordingly)\n",
        "# IMG_SIZE = (128, 128)  # You can adjust the size based on your dataset\n",
        "\n",
        "# # Build the CNN model with adjustments\n",
        "# model = Sequential([\n",
        "#     Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "#     BatchNormalization(),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "#     Dropout(0.25),\n",
        "\n",
        "#     Conv2D(128, (3, 3), activation='relu'),\n",
        "#     BatchNormalization(),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "#     Dropout(0.25),\n",
        "\n",
        "#     Conv2D(256, (3, 3), activation='relu'),\n",
        "#     BatchNormalization(),\n",
        "#     MaxPooling2D((2, 2)),\n",
        "#     Dropout(0.25),\n",
        "\n",
        "#     Flatten(),\n",
        "#     Dense(512, activation='relu'),\n",
        "#     Dropout(0.5),\n",
        "#     Dense(y_train.shape[1], activation='linear')  # Output layer with the number of features\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kev8BW39m3Cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64bb0e4-2463-4974-f834-aaff8a4ef82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 140ms/step - loss: 11.8225 - mae: 2.5314 - val_loss: 5.3045 - val_mae: 1.8518\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 5.1225 - mae: 1.8343 - val_loss: 4.5447 - val_mae: 1.6943\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 4.2187 - mae: 1.6376 - val_loss: 3.9601 - val_mae: 1.5806\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 3.2503 - mae: 1.4255 - val_loss: 3.8094 - val_mae: 1.5587\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.8076 - mae: 1.3136 - val_loss: 3.0024 - val_mae: 1.3796\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.5794 - mae: 1.2589 - val_loss: 2.9806 - val_mae: 1.3733\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2717 - mae: 1.1668 - val_loss: 3.2756 - val_mae: 1.4429\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.4138 - mae: 1.1984 - val_loss: 2.9546 - val_mae: 1.3626\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2016 - mae: 1.1520 - val_loss: 2.5925 - val_mae: 1.2647\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.2738 - mae: 1.1552 - val_loss: 2.7453 - val_mae: 1.3131\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2.0849 - mae: 1.1131 - val_loss: 2.7812 - val_mae: 1.3185\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9056 - mae: 1.0668 - val_loss: 3.1964 - val_mae: 1.4198\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9923 - mae: 1.0761 - val_loss: 3.1179 - val_mae: 1.4007\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8706 - mae: 1.0399 - val_loss: 2.2902 - val_mae: 1.1818\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8748 - mae: 1.0467 - val_loss: 2.4762 - val_mae: 1.2389\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8470 - mae: 1.0295 - val_loss: 2.3531 - val_mae: 1.2057\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9326 - mae: 1.0543 - val_loss: 2.4358 - val_mae: 1.2161\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.8812 - mae: 1.0464 - val_loss: 2.5501 - val_mae: 1.2545\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1.8417 - mae: 1.0175 - val_loss: 2.6861 - val_mae: 1.2950\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.8363 - mae: 1.0261 - val_loss: 2.4134 - val_mae: 1.2152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_054827.h5\n",
            "Deleted old model: /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_054624.h5\n",
            "Latest model: /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_054827.h5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n",
        "\n",
        "# Define the output directory\n",
        "output_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Generate a filename with the current date and time\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = os.path.join(output_dir, f\"blast_analysis_model_{timestamp}.h5\")\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Keep only the latest model\n",
        "saved_models = sorted(\n",
        "    [os.path.join(output_dir, file) for file in os.listdir(output_dir) if file.endswith('.h5')],\n",
        "    key=os.path.getmtime,\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "# Remove older models, keeping the latest one\n",
        "for old_model in saved_models[1:]:\n",
        "    os.remove(old_model)\n",
        "    print(f\"Deleted old model: {old_model}\")\n",
        "\n",
        "print(f\"Latest model: {saved_models[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How to increase model performance\n",
        "# 1. Increase Model Depth:\n",
        "# Add more convolutional layers with more filters or experiment with different layer architectures.\n",
        "\n",
        "# 2. Use a Different Optimizer:\n",
        "# Try optimizers like RMSprop or SGD with momentum, or try fine-tuning the learning rate.\n",
        "\n",
        "# 3. Data Preprocessing:\n",
        "# Normalize your data before training (scaling pixel values to [0, 1]).\n",
        "# Consider using a validation split during training to ensure that the model generalizes better.\n",
        "# 4. Epoch Adjustment:\n",
        "# Increase epochs, but use a learning rate scheduler to adjust learning rates as training progresses to improve convergence.\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Use a learning rate scheduler to reduce the learning rate if the model stops improving\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the model with augmented data\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=32),\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=50,  # Increase epochs for more training\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Calculate accuracy manually for multi-output\n",
        "# Round the predictions and ground truth\n",
        "y_pred_rounded = np.rint(y_pred).astype(int)\n",
        "y_test_rounded = np.rint(y_test).astype(int)\n",
        "\n",
        "# Calculate accuracy for each output individually\n",
        "accuracies = []\n",
        "for i in range(y_pred_rounded.shape[1]):  # For each output (column)\n",
        "    accuracies.append(np.mean(y_pred_rounded[:, i] == y_test_rounded[:, i]))\n",
        "\n",
        "# Calculate the average accuracy across all outputs\n",
        "average_accuracy = np.mean(accuracies)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"R-squared (R2 Score): {r2:.4f}\")\n",
        "print(f\"Accuracy (Average across outputs): {average_accuracy:.4f}\")\n",
        "\n",
        "# Save the model as before\n",
        "output_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = os.path.join(output_dir, f\"blast_analysis_model_{timestamp}.h5\")\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Keep only the latest model\n",
        "saved_models = sorted(\n",
        "    [os.path.join(output_dir, file) for file in os.listdir(output_dir) if file.endswith('.h5')],\n",
        "    key=os.path.getmtime,\n",
        "    reverse=True\n",
        ")\n",
        "\n",
        "# Remove older models, keeping the latest one\n",
        "for old_model in saved_models[1:]:\n",
        "    os.remove(old_model)\n",
        "    print(f\"Deleted old model: {old_model}\")\n",
        "\n",
        "print(f\"Latest model: {saved_models[0]}\")"
      ],
      "metadata": {
        "id": "dnvR2rFSYGl4",
        "outputId": "9dbf7255-13a9-4936-e32e-039ddf9fbc32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 290ms/step - loss: 3.2624 - mae: 1.3906 - val_loss: 1.5648 - val_mae: 0.9436 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - loss: 2.2527 - mae: 1.1506 - val_loss: 1.6671 - val_mae: 0.9941 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 2.1946 - mae: 1.1500 - val_loss: 1.8135 - val_mae: 1.0502 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - loss: 2.2359 - mae: 1.1730 - val_loss: 1.7361 - val_mae: 1.0259 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 2.1627 - mae: 1.1428 - val_loss: 1.7383 - val_mae: 1.0256 - learning_rate: 5.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 2.1833 - mae: 1.1475 - val_loss: 1.7815 - val_mae: 1.0384 - learning_rate: 5.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - loss: 2.1817 - mae: 1.1534 - val_loss: 1.7307 - val_mae: 1.0218 - learning_rate: 5.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 2.1348 - mae: 1.1296 - val_loss: 1.7646 - val_mae: 1.0328 - learning_rate: 2.5000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 2.1149 - mae: 1.1334 - val_loss: 1.7833 - val_mae: 1.0387 - learning_rate: 2.5000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - loss: 2.2405 - mae: 1.1671 - val_loss: 1.7720 - val_mae: 1.0351 - learning_rate: 2.5000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 2.1166 - mae: 1.1309 - val_loss: 1.7578 - val_mae: 1.0305 - learning_rate: 1.2500e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - loss: 2.3270 - mae: 1.1884 - val_loss: 1.7583 - val_mae: 1.0307 - learning_rate: 1.2500e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - loss: 2.0842 - mae: 1.1131 - val_loss: 1.7490 - val_mae: 1.0277 - learning_rate: 1.2500e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 2.1110 - mae: 1.1229 - val_loss: 1.7654 - val_mae: 1.0331 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - loss: 2.2377 - mae: 1.1718 - val_loss: 1.7683 - val_mae: 1.0340 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 2.1595 - mae: 1.1393 - val_loss: 1.7700 - val_mae: 1.0346 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 2.1848 - mae: 1.1456 - val_loss: 1.7839 - val_mae: 1.0389 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 2.1729 - mae: 1.1359 - val_loss: 1.7759 - val_mae: 1.0364 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 2.2239 - mae: 1.1591 - val_loss: 1.7726 - val_mae: 1.0353 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 2.2119 - mae: 1.1575 - val_loss: 1.7726 - val_mae: 1.0352 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 2.3090 - mae: 1.1763 - val_loss: 1.7756 - val_mae: 1.0363 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 2.2966 - mae: 1.1792 - val_loss: 1.7773 - val_mae: 1.0369 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 2.1814 - mae: 1.1525 - val_loss: 1.7691 - val_mae: 1.0344 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - loss: 2.3411 - mae: 1.1963 - val_loss: 1.7824 - val_mae: 1.0386 - learning_rate: 1.0000e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 2.1083 - mae: 1.1185 - val_loss: 1.7894 - val_mae: 1.0408 - learning_rate: 1.0000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - loss: 2.1145 - mae: 1.1298 - val_loss: 1.7778 - val_mae: 1.0371 - learning_rate: 1.0000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 2.1289 - mae: 1.1258 - val_loss: 1.7758 - val_mae: 1.0366 - learning_rate: 1.0000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - loss: 2.1691 - mae: 1.1421 - val_loss: 1.7659 - val_mae: 1.0335 - learning_rate: 1.0000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 2.2134 - mae: 1.1621 - val_loss: 1.7520 - val_mae: 1.0291 - learning_rate: 1.0000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 2.2377 - mae: 1.1607 - val_loss: 1.7595 - val_mae: 1.0317 - learning_rate: 1.0000e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - loss: 2.1839 - mae: 1.1439 - val_loss: 1.7648 - val_mae: 1.0334 - learning_rate: 1.0000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - loss: 2.2463 - mae: 1.1690 - val_loss: 1.7734 - val_mae: 1.0364 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 2.1803 - mae: 1.1475 - val_loss: 1.7648 - val_mae: 1.0338 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - loss: 2.0765 - mae: 1.1205 - val_loss: 1.7595 - val_mae: 1.0323 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 2.2201 - mae: 1.1571 - val_loss: 1.7844 - val_mae: 1.0401 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 2.2890 - mae: 1.1842 - val_loss: 1.7685 - val_mae: 1.0351 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 2.2814 - mae: 1.1789 - val_loss: 1.7669 - val_mae: 1.0346 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 2.1765 - mae: 1.1527 - val_loss: 1.7682 - val_mae: 1.0351 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 2.3693 - mae: 1.1974 - val_loss: 1.7761 - val_mae: 1.0376 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 2.1252 - mae: 1.1314 - val_loss: 1.7887 - val_mae: 1.0416 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - loss: 2.0769 - mae: 1.1129 - val_loss: 1.7765 - val_mae: 1.0375 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 95ms/step - loss: 2.2611 - mae: 1.1637 - val_loss: 1.7617 - val_mae: 1.0327 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 2.2800 - mae: 1.1727 - val_loss: 1.7783 - val_mae: 1.0381 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - loss: 2.2579 - mae: 1.1716 - val_loss: 1.7810 - val_mae: 1.0389 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 2.1337 - mae: 1.1385 - val_loss: 1.7866 - val_mae: 1.0407 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 2.1284 - mae: 1.1288 - val_loss: 1.7667 - val_mae: 1.0344 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 2.3230 - mae: 1.1709 - val_loss: 1.7657 - val_mae: 1.0344 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - loss: 2.2687 - mae: 1.1682 - val_loss: 1.7613 - val_mae: 1.0329 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - loss: 2.3010 - mae: 1.1813 - val_loss: 1.7710 - val_mae: 1.0360 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - loss: 2.2805 - mae: 1.1704 - val_loss: 1.7666 - val_mae: 1.0346 - learning_rate: 1.0000e-05\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 1.0346\n",
            "Mean Squared Error (MSE): 1.7666\n",
            "R-squared (R2 Score): -0.2337\n",
            "Accuracy (Average across outputs): 0.3247\n",
            "Model saved to /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_055159.h5\n",
            "Deleted old model: /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_054827.h5\n",
            "Latest model: /content/drive/My Drive/pour_la_hackathon/MineAI/output/blast_analysis_model_20250115_055159.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "N-djdAwlm29K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c14f1d-347a-4edc-ccd9-fe7ead3cf2f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
            "Mapped grades for the new blast: [3, 3, 3, 3, 0, 3, 2, 1, 1, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 0, 0, 3]\n",
            "+------------------------------+------------------------+-------------------+------------------+---------------+----------------------------------------+---------------------------------------------------+-------------------+----------------+------------------------------+------------------+------------------+--------------------+------------------+---------------------+--------------------+------------------------------+------------------+---------------------+-----------------------------------------------+-----------------------------------------------------------------+----------------------------------------------------------------+----------------------------------------+\n",
            "|   Fragment Size Distribution |   Visual Fragmentation |   Boulders (>1 m) |   Fines (<10 mm) |   Most Blasts |   For Development and Pioneering Blast |   Digability (Ease of Excavation) - Simple Method |   Muckpile Height |   Swell Factor |   Fragmentation Distribution |   Muckpile Shape |   Blast Sequence |   Time Gap/Overlap |   Muckpile Throw |   Misfires/Blowouts |   Swell and Spread |   Fragmentation Distribution |   Muckpile Shape |   Misfires/Blowouts |   Confinement and Ejection (Stemming Quality) |   (Vibration Monitor data available) Fish Spawning season - Yes |   (Vibration Monitor data available) Fish Spawning season - No |   Vibration Monitor Data not available |\n",
            "+==============================+========================+===================+==================+===============+========================================+===================================================+===================+================+==============================+==================+==================+====================+==================+=====================+====================+==============================+==================+=====================+===============================================+=================================================================+================================================================+========================================+\n",
            "|                            3 |                      3 |                 3 |                3 |             0 |                                      3 |                                                 2 |                 1 |              1 |                            1 |                1 |                3 |                  3 |                3 |                   3 |                  2 |                            3 |                3 |                   3 |                                             3 |                                                               0 |                                                              0 |                                      3 |\n",
            "+------------------------------+------------------------+-------------------+------------------+---------------+----------------------------------------+---------------------------------------------------+-------------------+----------------+------------------------------+------------------+------------------+--------------------+------------------+---------------------+--------------------+------------------------------+------------------+---------------------+-----------------------------------------------+-----------------------------------------------------------------+----------------------------------------------------------------+----------------------------------------+\n",
            "Average for range (0, 3): 3\n",
            "Average for range (4, 5): 3\n",
            "Average for range (6, 10): 1\n",
            "Average for range (11, 14): 3\n",
            "Average for range (15, 18): 3\n",
            "Average for range (19, 19): 3\n",
            "Average for range (20, 22): 3\n",
            "Final grade of the blast: B\n",
            "Blast Quality Scorecard:\n",
            "\n",
            "Fragmentation Quality:\n",
            "  Grade: B\n",
            "  Recommendation: Increase explosive energy: Consider increasing the Powder Factor (PF) or using a more energetic explosive to achieve better fragmentation. Optimize hole diameter and adjust timing sequence.\n",
            "\n",
            "Flyrock and Safety:\n",
            "  Grade: B\n",
            "  Recommendation: Increase blast matting, expand safety zone, and reduce PF to prevent over-breaking of the rock.\n",
            "\n",
            "Digability:\n",
            "  Grade: F\n",
            "  Recommendation: Increase explosive energy, use delay blasting, and increase blast diameter.\n",
            "\n",
            "Timing and Sequencing:\n",
            "  Grade: B\n",
            "  Recommendation: Fine-tune delay sequences.\n",
            "\n",
            "Vibration and Overpressure:\n",
            "  Grade: B\n",
            "  Recommendation: Increase delay times, reduce explosive charge.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "\n",
        "#importing the given data from google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the file in Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "\n",
        "# Define image size for input shape\n",
        "IMG_SIZE = (128, 128)  # Example image size, adjust accordingly\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Read and preprocess a single image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_resized = cv2.resize(img, IMG_SIZE)  # Resize to IMG_SIZE\n",
        "    img_normalized = img_resized / 255.0  # Normalize pixel values\n",
        "    return img_normalized\n",
        "\n",
        "def predict_new_blast(model_path, new_frames_dir):\n",
        "    \"\"\"Predict features for a new set of frames.\"\"\"\n",
        "    # Load the trained model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Process new frames\n",
        "    new_features = []\n",
        "    frame_predictions = []  # To store individual frame predictions\n",
        "    image_files = os.listdir(new_frames_dir)\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(new_frames_dir, image_file)\n",
        "        img_feature = preprocess_image(image_path)\n",
        "        new_features.append(img_feature)\n",
        "\n",
        "        # Predict for the current frame\n",
        "        prediction = model.predict(np.expand_dims(img_feature, axis=0))  # Single frame prediction\n",
        "        frame_predictions.append(prediction[0])  # Store prediction for this frame\n",
        "\n",
        "    # Convert to numpy array and predict\n",
        "    new_features = np.array(new_features)\n",
        "    aggregated_prediction = np.mean(frame_predictions, axis=0)\n",
        "\n",
        "    return aggregated_prediction, frame_predictions, len(image_files)\n",
        "\n",
        "def map_predictions_to_grades(predictions):\n",
        "    \"\"\"Map predicted features to grades based on conditions.\"\"\"\n",
        "    grades = []\n",
        "    for pred in predictions:\n",
        "        if pred > 3.5:\n",
        "            grade = 4\n",
        "        elif 2.5 <= pred <= 3.5:\n",
        "            grade = 3\n",
        "        elif 1.5 <= pred <= 2.5:\n",
        "            grade = 2\n",
        "        elif 0.5 <= pred <= 1.5:  # Adjusted lower bound\n",
        "            grade = 1\n",
        "        else:\n",
        "            grade = 0\n",
        "        grades.append(grade)\n",
        "    return grades\n",
        "\n",
        "\n",
        "# Example usage\n",
        "new_frames_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/unknown_blast_frames\"\n",
        "model_save_path = \"/content/drive/My Drive/pour_la_hackathon/MineAI/blast_analysis_model.h5\"\n",
        "\n",
        "# Predict the features for the new blast frames\n",
        "predicted_features, individual_predictions, num_images = predict_new_blast(model_save_path, new_frames_dir)\n",
        "\n",
        "# Display number of images and individual predictions\n",
        "# print(f\"Number of images processed: {num_images}\")\n",
        "# print(f\"Individual frame predictions:\")\n",
        "# for i, pred in enumerate(individual_predictions):\n",
        "#     print(f\"Frame {i+1}: {pred}\")\n",
        "\n",
        "# Map the predicted features to grades based on the conditions\n",
        "final_grades = map_predictions_to_grades(predicted_features)\n",
        "print(\"Mapped grades for the new blast:\", final_grades)\n",
        "\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Column labels\n",
        "columns = [\n",
        "    \"Fragment Size Distribution\", \"Visual Fragmentation\", \"Boulders (>1 m)\", \"Fines (<10 mm)\",\n",
        "    \"Most Blasts\", \"For Development and Pioneering Blast\", \"Digability (Ease of Excavation) - Simple Method\",\n",
        "    \"Muckpile Height\", \"Swell Factor\", \"Fragmentation Distribution\", \"Muckpile Shape\",\n",
        "    \"Blast Sequence\", \"Time Gap/Overlap\", \"Muckpile Throw\", \"Misfires/Blowouts\", \"Swell and Spread\",\n",
        "    \"Fragmentation Distribution\", \"Muckpile Shape\", \"Misfires/Blowouts\",\n",
        "    \"Confinement and Ejection (Stemming Quality)\", \"(Vibration Monitor data available) Fish Spawning season - Yes\",\n",
        "    \"(Vibration Monitor data available) Fish Spawning season - No\", \"Vibration Monitor Data not available\"\n",
        "]\n",
        "\n",
        "# Grades for each column\n",
        "\n",
        "# Combine column labels and grades into a single table row\n",
        "table_data = [final_grades]\n",
        "\n",
        "# Display the table\n",
        "print(tabulate(table_data, headers=columns, tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "# Define the ranges for averaging\n",
        "ranges = [\n",
        "    (0, 3),  # arr[0] to arr[3] is for fragmentation quality\n",
        "    (4, 5),  # arr[4] and arr[5] is for flyrock safety\n",
        "    (6, 10), # arr[6] to arr[10] is for digability\n",
        "    (11, 14),# arr[11] to arr[14] is for blast timing\n",
        "    (15, 18),# arr[15] to arr[18] is for powder factor and energy distribution\n",
        "    (19, 19),# arr[19] only is for confinement and ejection\n",
        "    (20, 22) # arr[20] to arr[22] is for vibration and overpressure\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Function to calculate average ignoring zeros\n",
        "def average_ignore_zeros(arr):\n",
        "    non_zero_elements = [x for x in arr if x != 0]\n",
        "    if not non_zero_elements:  # If all elements are zero\n",
        "        return 0\n",
        "    return sum(non_zero_elements) / len(non_zero_elements)\n",
        "\n",
        "\n",
        "# Calculate averages for the specified ranges\n",
        "averages = []\n",
        "for start, end in ranges:\n",
        "    subset = final_grades[start:end+1]\n",
        "    avg = average_ignore_zeros(subset)\n",
        "    averages.append(avg)\n",
        "\n",
        "# Output the averages\n",
        "# for i, avg in enumerate(averages, start=1):\n",
        "    # print(f\"Average for range {ranges[i-1]}: {avg:.2f}\")\n",
        "\n",
        "# Output the approximated averages\n",
        "for i, avg in enumerate(averages, start=1):\n",
        "    approximated_avg = round(avg)  # Round the average to the nearest integer\n",
        "    # print(f\"Average for range (rounded off) {ranges[i-1]}: {approximated_avg}\")\n",
        "\n",
        "# Output the approximated averages and store them\n",
        "approximated_averages = []\n",
        "\n",
        "for i, avg in enumerate(averages, start=1):\n",
        "    approximated_avg = round(avg)  # Round the average to the nearest integer\n",
        "    approximated_averages.append(approximated_avg)\n",
        "    print(f\"Average for range {ranges[i-1]}: {approximated_avg}\")\n",
        "\n",
        "# Compute the mean of the rounded averages (ignoring 0)\n",
        "non_zero_approximated_averages = [x for x in approximated_averages if x != 0]\n",
        "overall_mean = sum(non_zero_approximated_averages) / len(non_zero_approximated_averages)\n",
        "\n",
        "# Round the overall mean\n",
        "final_mean = round(overall_mean)\n",
        "# print(f\"Overall mean of rounded averages: {final_mean}\")\n",
        "\n",
        "# Define grade mapping\n",
        "grade_mapping = {4: 'A', 3: 'B', 2: 'C', 1: 'F'}\n",
        "\n",
        "# Get the final letter grade\n",
        "final_letter_grade = grade_mapping.get(final_mean, 'Invalid Grade')\n",
        "print(f\"Final grade of the blast: {final_letter_grade}\")\n",
        "\n",
        "# Define the ranges for averaging\n",
        "ranges = [\n",
        "    (0, 3),  # arr[0] to arr[3] is for fragmentation quality\n",
        "    (4, 5),  # arr[4] and arr[5] is for flyrock safety\n",
        "    (6, 10), # arr[6] to arr[10] is for digability\n",
        "    (11, 14),# arr[11] to arr[14] is for blast timing\n",
        "    (15, 18),# arr[15] to arr[18] is for powder factor and energy distribution\n",
        "    (19, 19),# arr[19] only is for confinement and ejection\n",
        "    (20, 22) # arr[20] to arr[22] is for vibration and overpressure\n",
        "]\n",
        "\n",
        "# Function to calculate average ignoring zeros\n",
        "def average_ignore_zeros(arr):\n",
        "    non_zero_elements = [x for x in arr if x != 0]\n",
        "    if not non_zero_elements:  # If all elements are zero\n",
        "        return 0\n",
        "    return sum(non_zero_elements) / len(non_zero_elements)\n",
        "\n",
        "# Calculate averages for the specified ranges\n",
        "averages = []\n",
        "for start, end in ranges:\n",
        "    subset = final_grades[start:end+1]\n",
        "    avg = average_ignore_zeros(subset)\n",
        "    averages.append(avg)\n",
        "\n",
        "# Output the approximated averages and convert to grades\n",
        "approximated_averages = []\n",
        "hashmap = {\n",
        "    \"Fragmentation Quality\": None,\n",
        "    \"Flyrock and Safety\": None,\n",
        "    \"Digability\": None,\n",
        "    \"Blast Timing\": None,\n",
        "    \"Powder Factor and Energy Distribution\": None,\n",
        "    \"Confinement and Ejection\": None,\n",
        "    \"Vibration and Overpressure\": None\n",
        "}\n",
        "\n",
        "# Define grade mapping\n",
        "grade_mapping = {4: 'A', 3: 'B', 2: 'C', 1: 'F'}\n",
        "\n",
        "for i, avg in enumerate(averages, start=1):\n",
        "    approximated_avg = round(avg)  # Round the average to the nearest integer\n",
        "    approximated_averages.append(approximated_avg)\n",
        "\n",
        "    # Convert the approximated average to grade\n",
        "    grade = grade_mapping.get(approximated_avg, 'Invalid Grade')\n",
        "\n",
        "    key = list(hashmap.keys())[i - 1]\n",
        "    hashmap[key] = grade\n",
        "\n",
        "# Compute the mean of the rounded averages (ignoring 0)\n",
        "non_zero_approximated_averages = [x for x in approximated_averages if x != 0]\n",
        "overall_mean = sum(non_zero_approximated_averages) / len(non_zero_approximated_averages)\n",
        "\n",
        "# Round the overall mean\n",
        "final_mean = round(overall_mean)\n",
        "\n",
        "# Convert the final mean to a grade\n",
        "final_letter_grade = grade_mapping.get(final_mean, 'Invalid Grade')\n",
        "\n",
        "\n",
        "# print(f\"\\nFinal grade of the blast: {final_letter_grade}\")\n",
        "\n",
        "# Corrected recommendations dictionary with only relevant keys\n",
        "recommendations = {\n",
        "    \"Fragmentation Quality\": {\n",
        "        \"A\": \"No improvement needed. The blast is well-executed, and fragmentation is ideal for excavation.\",\n",
        "        \"B\": \"Increase explosive energy: Consider increasing the Powder Factor (PF) or using a more energetic explosive to achieve better fragmentation. Optimize hole diameter and adjust timing sequence.\",\n",
        "        \"C\": \"Increase explosive charge and burden. Use higher-energy explosives or boosters to improve fragmentation.\",\n",
        "        \"F\": \"Increase charge, reduce hole spacing, change detonation sequence, and optimize stemming.\"\n",
        "    },\n",
        "    \"Flyrock and Safety\": {\n",
        "        \"A\": \"No improvement needed. The blast was executed safely with controlled flyrock.\",\n",
        "        \"B\": \"Increase blast matting, expand safety zone, and reduce PF to prevent over-breaking of the rock.\",\n",
        "        \"C\": \"Increase stemming height, improve initiation sequence, and increase burden.\",\n",
        "        \"F\": \"Increase safety zone, use blast barriers/mats, reassess explosive charge, and improve initiation design.\"\n",
        "    },\n",
        "    \"Digability\": {\n",
        "        \"A\": \"No improvement needed. The blast has achieved ideal material movement and fragmentation.\",\n",
        "        \"B\": \"Optimize blast timing, adjust stemming height.\",\n",
        "        \"C\": \"Increase explosive charge, increase burden/spacing for energy distribution.\",\n",
        "        \"F\": \"Increase explosive energy, use delay blasting, and increase blast diameter.\"\n",
        "    },\n",
        "    \"Vibration and Overpressure\": {\n",
        "        \"A\": \"No improvement needed. The blast was within safe vibration limits.\",\n",
        "        \"B\": \"Increase delay times, reduce explosive charge.\",\n",
        "        \"C\": \"Adjust timing, increase stemming height.\",\n",
        "        \"F\": \"Revisit blast design, add blast mats, reassess explosive type.\"\n",
        "    },\n",
        "    \"Timing and Sequencing\": {\n",
        "        \"A\": \"No improvement needed. The blast was timed and sequenced well.\",\n",
        "        \"B\": \"Fine-tune delay sequences.\",\n",
        "        \"C\": \"Adjust timing significantly, minimize gaps in detonation sequence.\",\n",
        "        \"F\": \"Rework the entire timing and sequencing strategy.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define the ranges for averaging (only the relevant ranges are included)\n",
        "ranges = [\n",
        "    (0, 3),  # Fragmentation Quality\n",
        "    (4, 5),  # Flyrock and Safety\n",
        "    (6, 10), # Digability\n",
        "    (11, 14),# Blast Timing\n",
        "    (20, 22) # Vibration and Overpressure\n",
        "]\n",
        "\n",
        "# Function to calculate average ignoring zeros\n",
        "def average_ignore_zeros(arr):\n",
        "    non_zero_elements = [x for x in arr if x != 0]\n",
        "    if not non_zero_elements:  # If all elements are zero\n",
        "        return 0\n",
        "    return sum(non_zero_elements) / len(non_zero_elements)\n",
        "\n",
        "# Calculate averages for the specified ranges\n",
        "averages = []\n",
        "for start, end in ranges:\n",
        "    subset = final_grades[start:end+1]\n",
        "    avg = average_ignore_zeros(subset)\n",
        "    averages.append(avg)\n",
        "\n",
        "# Output the approximated averages and convert to grades\n",
        "approximated_averages = []\n",
        "hashmap = {\n",
        "    \"Fragmentation Quality\": None,\n",
        "    \"Flyrock and Safety\": None,\n",
        "    \"Digability\": None,\n",
        "    \"Timing and Sequencing\": None,\n",
        "    \"Vibration and Overpressure\": None\n",
        "}\n",
        "\n",
        "# Define grade mapping\n",
        "grade_mapping = {4: 'A', 3: 'B', 2: 'C', 1: 'F'}\n",
        "\n",
        "# Populate the hashmap with grades and recommendations\n",
        "for i, avg in enumerate(averages, start=1):\n",
        "    approximated_avg = round(avg)  # Round the average to the nearest integer\n",
        "    approximated_averages.append(approximated_avg)\n",
        "\n",
        "    grade = grade_mapping.get(approximated_avg, 'Invalid Grade')\n",
        "    key = list(hashmap.keys())[i - 1]\n",
        "    hashmap[key] = grade\n",
        "\n",
        "# Generate the scorecard with recommendations\n",
        "scorecard = {}\n",
        "for parameter, grade in hashmap.items():\n",
        "    scorecard[parameter] = {\n",
        "        \"Grade\": grade,\n",
        "        \"Recommendation\": recommendations[parameter].get(grade, 'No recommendation available')\n",
        "    }\n",
        "\n",
        "# Output the scorecard\n",
        "print(\"Blast Quality Scorecard:\")\n",
        "for parameter, details in scorecard.items():\n",
        "    print(f\"\\n{parameter}:\")\n",
        "    print(f\"  Grade: {details['Grade']}\")\n",
        "    print(f\"  Recommendation: {details['Recommendation']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9E6riyBAdnbm",
        "outputId": "ef02201d-54dd-4b4a-eae2-7abe5a7f27e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final grade of the blast: B\n",
            "Blast Quality Scorecard:\n",
            "\n",
            "Fragmentation Quality:\n",
            "  Grade: B\n",
            "  Recommendation: Increase explosive energy: Consider increasing the Powder Factor (PF) or using a more energetic explosive to achieve better fragmentation. Optimize hole diameter and adjust timing sequence.\n",
            "\n",
            "Flyrock and Safety:\n",
            "  Grade: B\n",
            "  Recommendation: Increase blast matting, expand safety zone, and reduce PF to prevent over-breaking of the rock.\n",
            "\n",
            "Digability:\n",
            "  Grade: F\n",
            "  Recommendation: Increase explosive energy, use delay blasting, and increase blast diameter.\n",
            "\n",
            "Timing and Sequencing:\n",
            "  Grade: B\n",
            "  Recommendation: Fine-tune delay sequences.\n",
            "\n",
            "Vibration and Overpressure:\n",
            "  Grade: B\n",
            "  Recommendation: Increase delay times, reduce explosive charge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eZyyXP6dm20Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAwma_Oym2xR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StlMUwjqm2uO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zzZROC-m2q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAtCezn_m2nt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iogHMe8Om2k2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1GxQ87YJ-fnsrTiabGiPOQ7ocT-MTx2oE",
      "authorship_tag": "ABX9TyPvv594jECMX/pyg0mSOyb7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}