{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neversettlejay/mineai_cote_gold/blob/no_validation/MineAI_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR42mOT4riKV"
      },
      "source": [
        "# MineAI - Optimizing Open-Pit Blast Performance with Machine Learning\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project focuses on using algorithms and available data to rate the effectiveness of open pit blasts. The goal is to suggest optimal parameters that can improve drill and blast efficiency, as well as reduce the deviation between planned and actual drilling results (e.g., drill hole deviations, blast outcomes, etc.). Through data analysis and predictive modeling, the project aims to enhance mining operations by optimizing blast designs, improving fragmentation, and reducing unplanned costs due to inefficiencies in drilling and blasting.\n",
        "\n",
        "\n",
        "## Team Members\n",
        "\n",
        "* Manav Chaudhary - Mining Engineer\n",
        "* Shrey Patel - Machine Learning Engineer\n",
        "* Soham Salakhana - Mining Engineer\n",
        "* Shakil Kalvatar - Mining Engineer\n",
        "* Jay Rathod - Software Engineer\n",
        "\n",
        "\n",
        "## Data and Methodology\n",
        "\n",
        "This project will leverage:\n",
        "\n",
        "* Historical data from past drill and blast operations\n",
        "* Sensor data from the mine, including real-time measurements of blast outcomes and drill hole characteristics\n",
        "* Statistical methods, machine learning algorithms, and optimization techniques to rate blast performance\n",
        "* Suggestions for optimizing parameters like drill depth, spacing, and blast charge amounts\n",
        "\n",
        "\n",
        "## Key Objectives\n",
        "\n",
        "* Rate the success of each blast based on fragmentation size, efficiency, and deviation from the planned design.\n",
        "* Use machine learning algorithms to identify patterns in the data and suggest improvements to drill and blast parameters.\n",
        "* Propose changes to the drilling process to reduce deviation and optimize efficiency, ultimately improving cost and time savings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ48s_oLsKGh"
      },
      "source": [
        "# Installing Dependencies\n",
        "\n",
        "This section outlines the necessary steps to install the required dependencies for this project.\n",
        "\n",
        "We will be using the following libraries:\n",
        "\n",
        "* **pdf2image:**  Converts PDF files to images for analysis.\n",
        "* **imagehash:**  Generates perceptual hashes of images for comparison and similarity detection.\n",
        "* **poppler-utils:** Provides utilities for working with PDF files, including rendering and conversion.\n",
        "* **opencv-python:**  Open Source Computer Vision Library for image and video processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd64Olfd4nk0",
        "outputId": "de577840-532e-4cea-f68c-a2a9b087e04f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (11.1.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 179, in _eval_op\n",
            "    spec = Specifier(\"\".join([op.serialize(), rhs]))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/specifiers.py\", line 237, in __init__\n",
            "    raise InvalidSpecifier(f\"Invalid specifier: '{spec}'\")\n",
            "pip._vendor.packaging.specifiers.InvalidSpecifier: Invalid specifier: '==dev'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in _compute_dependencies\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in <listcomp>\n",
            "    dm[s_extra] = [r for r in reqs_for_extra(extra) if r not in common]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3086, in reqs_for_extra\n",
            "    if not req.marker or req.marker.evaluate({'extra': extra}):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 325, in evaluate\n",
            "    return _evaluate_markers(self._markers, current_environment)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 225, in _evaluate_markers\n",
            "    groups[-1].append(_eval_op(lhs_value, op, rhs_value))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 179, in _eval_op\n",
            "    spec = Specifier(\"\".join([op.serialize(), rhs]))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1685, in print\n",
            "    render_options = self.options.update(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 983, in options\n",
            "    max_height=self.size.height,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1003, in size\n",
            "    if self.is_dumb_terminal:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 977, in is_dumb_terminal\n",
            "    return self.is_terminal and is_dumb\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 931, in is_terminal\n",
            "    @property\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting PyWavelets (from imagehash)\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.13.1)\n",
            "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "^C\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies\n",
        "\n",
        "!pip install pdf2image\n",
        "!pip install imagehash\n",
        "!apt-get install -y poppler-utils\n",
        "# !pip uninstall -y opencv-python opencv-python-headless\n",
        "!nvidia-smi\n",
        "!pip install opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMyh8BjOL60c"
      },
      "outputs": [],
      "source": [
        "# To use GPU\n",
        "# Remove any existing OpenCV installations\n",
        "# !pip uninstall -y opencv-python opencv-python-headless\n",
        "\n",
        "# # Install dependencies\n",
        "# !apt-get update && apt-get install -y \\\n",
        "#     build-essential cmake git unzip pkg-config \\\n",
        "#     libjpeg-dev libpng-dev libtiff-dev \\\n",
        "#     libavcodec-dev libavformat-dev libswscale-dev \\\n",
        "#     libv4l-dev libxvidcore-dev libx264-dev \\\n",
        "#     libgtk-3-dev libcanberra-gtk* \\\n",
        "#     libatlas-base-dev gfortran python3-dev \\\n",
        "#     libdc1394-22-dev libopenexr-dev libgstreamer-plugins-base1.0-dev \\\n",
        "#     libgstreamer1.0-dev libgphoto2-dev libeigen3-dev\n",
        "\n",
        "# # Clone OpenCV repositories\n",
        "# !git clone https://github.com/opencv/opencv.git\n",
        "# !git clone https://github.com/opencv/opencv_contrib.git\n",
        "\n",
        "# # Create a build directory\n",
        "# !mkdir -p opencv/build\n",
        "# %cd opencv/build\n",
        "\n",
        "# # Configure the build with CUDA support\n",
        "# !cmake -D CMAKE_BUILD_TYPE=RELEASE \\\n",
        "#        -D CMAKE_INSTALL_PREFIX=/usr/local \\\n",
        "#        -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \\\n",
        "#        -D WITH_CUDA=ON \\\n",
        "#        -D ENABLE_FAST_MATH=ON \\\n",
        "#        -D CUDA_FAST_MATH=ON \\\n",
        "#        -D WITH_CUDNN=ON \\\n",
        "#        -D OPENCV_DNN_CUDA=ON \\\n",
        "#        -D BUILD_opencv_python3=ON ..\n",
        "\n",
        "# # Build OpenCV (this might take a while)\n",
        "# !make -j$(nproc)\n",
        "\n",
        "# # Install the newly built OpenCV\n",
        "# !make install\n",
        "# !ldconfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fODMbgqyyAaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31d0b46-0445-4277-c8a3-1c9d8649fae0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# TO check whether GPU can be used\n",
        "import cv2\n",
        "print(cv2.cuda.getCudaEnabledDeviceCount())  # Should print a positive integer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNCj1g_wmzLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38988f4e-eb18-4f74-803f-58ab72238df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "\n",
        "#importing the given data from google drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the file in Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SKYkNe10zGbG"
      },
      "outputs": [],
      "source": [
        "#extract images from pdf\n",
        "import os\n",
        "import shutil\n",
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n",
        "from pdf2image import convert_from_path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base directory path in Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "\n",
        "# Define the main directories\n",
        "main_folders = [\"data\"]\n",
        "\n",
        "# --- CREATE CORRECT STRUCTURE AND EXTRACT IMAGES ---\n",
        "for main_folder in main_folders:\n",
        "    main_folder_path = os.path.join(parent_directory_path, main_folder)\n",
        "\n",
        "    for subfolder in os.listdir(main_folder_path):\n",
        "        subfolder_path = os.path.join(main_folder_path, subfolder)\n",
        "\n",
        "        # Check if it's a directory\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Create a 'report' folder if it doesn't exist\n",
        "            report_folder = os.path.join(subfolder_path, 'report')\n",
        "            os.makedirs(report_folder, exist_ok=True)\n",
        "\n",
        "            # Find all PDF files in the subfolder\n",
        "            pdf_files = [f for f in os.listdir(subfolder_path) if f.endswith('.pdf')]\n",
        "\n",
        "            for pdf_file in pdf_files:\n",
        "                pdf_path = os.path.join(subfolder_path, pdf_file)\n",
        "\n",
        "                # Create a subfolder inside 'report' based on the PDF name\n",
        "                pdf_name = os.path.splitext(pdf_file)[0]\n",
        "                pdf_report_folder = os.path.join(report_folder, pdf_name)\n",
        "                os.makedirs(pdf_report_folder, exist_ok=True)\n",
        "\n",
        "                # Convert PDF to images\n",
        "                try:\n",
        "                    images = convert_from_path(pdf_path)\n",
        "                    for i, image in enumerate(images):\n",
        "                        image_path = os.path.join(pdf_report_folder, f'image_{i + 1}.jpg')\n",
        "                        image.save(image_path, 'JPEG')\n",
        "\n",
        "                    print(f\"Extracted images from {pdf_file} saved in {pdf_report_folder}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {pdf_file}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEqMbQmKKZor",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "130f8030-796b-41ed-b3a7-021cf19362d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/328_109\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/340_102\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_103\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_108\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_121\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/364_303\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_312\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_138\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_137\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_132\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/352_131\n",
            "/content/drive/My Drive/pour_la_hackathon/MineAI/data/364_105\n"
          ]
        }
      ],
      "source": [
        "#to list directories\n",
        "import os\n",
        "\n",
        "# Assuming you've already mounted your Google Drive\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "data_folder = os.path.join(parent_directory_path, 'data')\n",
        "\n",
        "# List subdirectories\n",
        "for subdirectory in os.listdir(data_folder):\n",
        "    subdirectory_path = os.path.join(data_folder, subdirectory)\n",
        "    if os.path.isdir(subdirectory_path):\n",
        "        print(subdirectory_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvyNm4wSH3D7"
      },
      "outputs": [],
      "source": [
        "#crop video (moving object)\n",
        "import os\n",
        "import logging\n",
        "import cv2\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Define directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')\n",
        "output_folder = os.path.join(parent_directory_path, 'processed_videos')\n",
        "\n",
        "# Subfolders to process\n",
        "subfolders = ['C1_328_109', 'C1_340_102', 'C1_352_103', 'C1_352_108', 'C1_352_137', 'C1_352_132',\n",
        "              'C1_352_131', 'C1_352_121', 'C1_364_303', 'C1_364_105', 'C1_352_312', 'C1_352_138']\n",
        "\n",
        "# Supported video extensions\n",
        "video_extensions = ['.mp4', '.MP4', '.avi', '.AVI', '.mov', '.MOV', '.mkv', '.MKV']\n",
        "\n",
        "# Ensure output directory structure exists\n",
        "for subfolder in subfolders:\n",
        "    os.makedirs(os.path.join(output_folder, subfolder), exist_ok=True)\n",
        "\n",
        "# Initialize YOLOv8 model\n",
        "model = YOLO(\"yolov8s.pt\")  # Load the pretrained model\n",
        "\n",
        "# Define helper functions\n",
        "def box_center(coords):\n",
        "    left, top, right, bottom = coords\n",
        "    return [(left + right) / 2, (top + bottom) / 2]\n",
        "\n",
        "def adjust_box_size(coords, box_width, box_height):\n",
        "    center_x, center_y = box_center(coords)\n",
        "    return [\n",
        "        center_x - box_width / 2, center_y - box_height / 2,\n",
        "        center_x + box_width / 2, center_y + box_height / 2\n",
        "    ]\n",
        "\n",
        "def adjust_boundaries(coords, screen):\n",
        "    left, top, right, bottom = coords\n",
        "    width, height = screen\n",
        "    if left < 0:\n",
        "        right -= left\n",
        "        left = 0\n",
        "    if top < 0:\n",
        "        bottom -= top\n",
        "        top = 0\n",
        "    if right > width:\n",
        "        left -= (right - width)\n",
        "        right = width\n",
        "    if bottom > height:\n",
        "        top -= (bottom - height)\n",
        "        bottom = height\n",
        "    return [round(left), round(top), round(right), round(bottom)]\n",
        "\n",
        "def check_video_empty(vid_capture):\n",
        "    \"\"\"Check if a video is empty or corrupt.\"\"\"\n",
        "    if vid_capture.isOpened() == False:\n",
        "        return True\n",
        "    ret, frame = vid_capture.read()\n",
        "    if not ret or frame is None:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_steady_frame(frame, last_frame, threshold=5):\n",
        "    \"\"\"Check if the current frame is steady (no significant changes).\"\"\"\n",
        "    if last_frame is None:\n",
        "        return False\n",
        "    # Compute the difference between the current and the previous frame\n",
        "    diff = cv2.absdiff(frame, last_frame)\n",
        "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "    non_zero_count = cv2.countNonZero(diff_gray)\n",
        "    if non_zero_count < threshold:\n",
        "        return True  # Steady frame\n",
        "    return False\n",
        "\n",
        "# Process videos\n",
        "for subfolder in subfolders:\n",
        "    input_path = os.path.join(video_folder, subfolder)\n",
        "    output_path = os.path.join(output_folder, subfolder)\n",
        "\n",
        "    for file_name in os.listdir(input_path):\n",
        "        if os.path.splitext(file_name)[1] in video_extensions:\n",
        "            input_video = os.path.join(input_path, file_name)\n",
        "            output_video = os.path.join(output_path, f\"processed_{subfolder}.mp4\")\n",
        "\n",
        "            logger.info(f\"Processing video: {input_video}\")\n",
        "\n",
        "            # Open input video\n",
        "            vid_capture = cv2.VideoCapture(input_video)\n",
        "            fps = int(vid_capture.get(cv2.CAP_PROP_FPS))\n",
        "            width = int(vid_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(vid_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "            # Check if the video is empty or corrupt\n",
        "            if check_video_empty(vid_capture):\n",
        "                logger.warning(f\"Skipping empty or corrupt video: {input_video}\")\n",
        "                continue\n",
        "\n",
        "            # Initialize cropping box\n",
        "            box_width, box_height = 500, 500\n",
        "            default_coords = [100, 100, 600, 600]  # Default box\n",
        "            last_box_coords = default_coords\n",
        "            last_frame = None\n",
        "\n",
        "            # Open output video stream\n",
        "            output_writer = cv2.VideoWriter(\n",
        "                output_video,\n",
        "                cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "                fps,\n",
        "                (box_width, box_height)\n",
        "            )\n",
        "\n",
        "            # Process video frames\n",
        "            frame_counter = 0\n",
        "            steady_frame_counter = 0  # To track how many steady frames\n",
        "            min_frames = 5 * fps  # Ensure the video is at least 5 seconds long\n",
        "            while True:\n",
        "                ret, frame = vid_capture.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Check if the frame is steady\n",
        "                if is_steady_frame(frame, last_frame):\n",
        "                    steady_frame_counter += 1\n",
        "                else:\n",
        "                    steady_frame_counter = 0  # Reset if motion is detected\n",
        "\n",
        "                # YOLO detection\n",
        "                results = model.predict(source=frame, conf=0.5, iou=0.1)\n",
        "                boxes = results[0].boxes\n",
        "\n",
        "                if boxes:\n",
        "                    # Use the first detected box\n",
        "                    box = boxes[0].xyxy[0].cpu().numpy().astype(int)\n",
        "                    last_box_coords = adjust_box_size(box, box_width, box_height)\n",
        "                    last_box_coords = adjust_boundaries(last_box_coords, [width, height])\n",
        "\n",
        "                # Use the last known cropping box\n",
        "                box_left, box_top, box_right, box_bottom = last_box_coords\n",
        "\n",
        "                # Crop and write frame\n",
        "                cropped_frame = frame[box_top:box_bottom, box_left:box_right]\n",
        "                output_writer.write(cropped_frame)\n",
        "\n",
        "                # Update last frame for steady check\n",
        "                last_frame = frame\n",
        "\n",
        "                frame_counter += 1\n",
        "\n",
        "            # Ensure video has sufficient length\n",
        "            if frame_counter < min_frames:\n",
        "                logger.info(f\"Padding {min_frames - frame_counter} frames to video {output_video}\")\n",
        "                padding_frame = cropped_frame.copy()\n",
        "                for _ in range(min_frames - frame_counter):\n",
        "                    output_writer.write(padding_frame)\n",
        "\n",
        "            # Log if there were many steady frames\n",
        "            if steady_frame_counter > 50:\n",
        "                logger.info(f\"Detected {steady_frame_counter} steady frames in {input_video}\")\n",
        "\n",
        "            # Release resources\n",
        "            vid_capture.release()\n",
        "            output_writer.release()\n",
        "            logger.info(f\"Saved processed video to {output_video}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PQFsMbvhFLy1"
      },
      "outputs": [],
      "source": [
        "#extract frames from video every 300 ms\n",
        "import os\n",
        "import cv2\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')  # Path to the \"data\" folder\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(extracted_frames_dir, exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'frame_extraction.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Common video file extensions\n",
        "video_extensions = ['.mp4', '.MP4', '.avi', '.AVI', '.mov', '.MOV', '.mkv', '.MKV']\n",
        "\n",
        "def extract_frames(video_path, output_dir, frame_step=10):\n",
        "    \"\"\"\n",
        "    Extract frames from a video and save them based on timestamps in milliseconds.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the video file.\n",
        "        output_dir (str): Directory to save the frames.\n",
        "        frame_step (int): Interval to save frames (e.g., every nth frame).\n",
        "    \"\"\"\n",
        "    video_name = os.path.basename(video_path).split('.')[0]\n",
        "    video_frames_dir = os.path.join(output_dir, video_name)\n",
        "    os.makedirs(video_frames_dir, exist_ok=True)  # Create a subdirectory for the video\n",
        "\n",
        "    logging.info(f\"Processing video: {video_name}\")\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        logging.error(f\"Failed to open video: {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)  # Frame rate\n",
        "    frame_count = 0\n",
        "    saved_frames = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            logging.info(f\"End of video reached: {video_path}\")\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % frame_step != 0:\n",
        "            continue\n",
        "\n",
        "        # Get timestamp in milliseconds\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))  # Get timestamp in milliseconds\n",
        "\n",
        "        # Save frame with timestamp\n",
        "        frame_filename = os.path.join(video_frames_dir, f\"frame_{timestamp_ms:012d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        saved_frames += 1\n",
        "\n",
        "    cap.release()\n",
        "    logging.info(f\"Saved {saved_frames} frames from video: {video_name}\")\n",
        "\n",
        "def process_all_videos(video_folder, output_dir):\n",
        "    \"\"\"\n",
        "    Processes all videos in a folder and its subfolders, extracting frames.\n",
        "\n",
        "    Args:\n",
        "        video_folder (str): Directory containing all videos.\n",
        "        output_dir (str): Directory to save extracted frames.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for videos in folder: {video_folder}\")\n",
        "    files_found = False\n",
        "    for root, dirs, files in os.walk(video_folder):\n",
        "        for file in files:\n",
        "            if any(file.endswith(ext) for ext in video_extensions):\n",
        "                files_found = True\n",
        "                video_path = os.path.join(root, file)\n",
        "                logging.info(f\"Processing video: {file} in {root}\")\n",
        "                extract_frames(video_path, output_dir)\n",
        "\n",
        "    if not files_found:\n",
        "        logging.warning(f\"No video files found in {video_folder} or its subfolders.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting frame extraction process...\")\n",
        "    process_all_videos(video_folder, extracted_frames_dir)\n",
        "    logging.info(\"Frame extraction process completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_qG2XmYa8jr"
      },
      "outputs": [],
      "source": [
        "#conver to greyscale\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import logging\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'  # Replace with your actual path\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "extracted_frames_greyscale_dir = os.path.join(parent_directory_path, 'extracted_frames_greyscale')\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(extracted_frames_greyscale_dir, exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'greyscale_conversion.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def convert_to_greyscale(input_dir, output_dir):\n",
        "    \"\"\"\n",
        "    Converts all images in a directory and its subfolders to greyscale using glob.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for images in folder: {input_dir}\")\n",
        "\n",
        "    # Use glob to find all image files (adjust the pattern if needed)\n",
        "    image_files = glob.glob(os.path.join(input_dir, '**', 'frame_*.jpg'), recursive=True)\n",
        "\n",
        "    for image_path in image_files:\n",
        "        try:\n",
        "            # Read the image\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                logging.warning(f\"Failed to read image: {image_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Convert to greyscale\n",
        "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Construct the output path using string manipulation\n",
        "            relative_path = os.path.relpath(image_path, input_dir)\n",
        "            output_image_path = os.path.join(output_dir, relative_path)\n",
        "            output_dir_name = os.path.dirname(output_image_path)\n",
        "            os.makedirs(output_dir_name, exist_ok=True)  # Create output directory\n",
        "\n",
        "            # Save the greyscale image\n",
        "            cv2.imwrite(output_image_path, gray_img)\n",
        "            logging.info(f\"Converted {image_path} to greyscale and saved to {output_image_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.exception(f\"Error processing {image_path}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting greyscale conversion process...\")\n",
        "    convert_to_greyscale(extracted_frames_dir, extracted_frames_greyscale_dir)\n",
        "    logging.info(\"Greyscale conversion process completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CW_rYI-IDPc"
      },
      "outputs": [],
      "source": [
        "#lukas kanade method\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# Directories\n",
        "parent_directory_path = '/content/drive/My Drive/pour_la_hackathon/MineAI'\n",
        "video_folder = os.path.join(parent_directory_path, 'data')  # Path to the \"data\" folder\n",
        "extracted_frames_dir = os.path.join(parent_directory_path, 'extracted_frames')\n",
        "lukas_kanade_dir = os.path.join(parent_directory_path, 'lukas_kanade')\n",
        "\n",
        "# Create Lukas Kanade subfolders\n",
        "subfolders = ['328_109', '340_102', '352_103', '352_108', '352_137', '352_132', '352_131', '352_121', '364_303', '364_105', '352_312', '352_138']\n",
        "for subfolder in subfolders:\n",
        "    os.makedirs(os.path.join(lukas_kanade_dir, subfolder), exist_ok=True)\n",
        "\n",
        "# Logging configuration\n",
        "logging.basicConfig(\n",
        "    filename=os.path.join(parent_directory_path, 'lukas_kanade.log'),\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "def compute_optical_flow(prev_gray, next_gray):\n",
        "    \"\"\"\n",
        "    Compute the optical flow between two consecutive frames using Lucas-Kanade method.\n",
        "\n",
        "    Args:\n",
        "        prev_gray (ndarray): Grayscale image of the previous frame.\n",
        "        next_gray (ndarray): Grayscale image of the current frame.\n",
        "\n",
        "    Returns:\n",
        "        flow (ndarray): Optical flow vectors.\n",
        "    \"\"\"\n",
        "    # Parameters for Lucas-Kanade optical flow\n",
        "    flow = cv2.calcOpticalFlowFarneback(\n",
        "        prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
        "    )\n",
        "    return flow\n",
        "\n",
        "def draw_optical_flow(flow, frame, filename):\n",
        "    \"\"\"\n",
        "    Draws the optical flow on the frame and saves the result.\n",
        "\n",
        "    Args:\n",
        "        flow (ndarray): Optical flow vectors.\n",
        "        frame (ndarray): Current frame.\n",
        "        filename (str): File name to save the frame with flow visualization.\n",
        "    \"\"\"\n",
        "    # Convert flow to polar coordinates\n",
        "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "\n",
        "    # Create an image to display the flow\n",
        "    hsv = np.zeros_like(frame)\n",
        "    hsv[..., 1] = 255\n",
        "    hsv[..., 0] = angle * 180 / np.pi / 2  # Hue represents direction\n",
        "    hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)  # Value represents magnitude\n",
        "\n",
        "    flow_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)  # Convert back to BGR for display\n",
        "\n",
        "    # Save the optical flow image\n",
        "    cv2.imwrite(filename, flow_bgr)\n",
        "\n",
        "def apply_lukas_kanade_to_frames(video_frames_dir, lukas_kanade_subfolder):\n",
        "    \"\"\"\n",
        "    Apply Lucas-Kanade optical flow to all extracted frames and save the flow visualization.\n",
        "\n",
        "    Args:\n",
        "        video_frames_dir (str): Directory containing extracted frames.\n",
        "        lukas_kanade_subfolder (str): Subfolder to save optical flow images.\n",
        "    \"\"\"\n",
        "    frames = sorted([f for f in os.listdir(video_frames_dir) if f.endswith('.jpg')])\n",
        "    prev_frame = None\n",
        "    prev_gray = None\n",
        "\n",
        "    for i, frame_filename in enumerate(frames):\n",
        "        frame_path = os.path.join(video_frames_dir, frame_filename)\n",
        "        frame = cv2.imread(frame_path)\n",
        "\n",
        "        # Convert the frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if prev_frame is not None:\n",
        "            # Compute optical flow between previous and current frame\n",
        "            flow = compute_optical_flow(prev_gray, gray_frame)\n",
        "\n",
        "            # Create the filename for saving the optical flow visualization\n",
        "            flow_filename = os.path.join(lukas_kanade_subfolder, frame_filename)\n",
        "\n",
        "            # Draw and save optical flow\n",
        "            draw_optical_flow(flow, frame, flow_filename)\n",
        "\n",
        "        prev_frame = frame\n",
        "        prev_gray = gray_frame\n",
        "\n",
        "def process_all_videos_for_lukas_kanade(extracted_frames_dir, lukas_kanade_dir):\n",
        "    \"\"\"\n",
        "    Process all videos' extracted frames for optical flow and save the results.\n",
        "\n",
        "    Args:\n",
        "        extracted_frames_dir (str): Directory containing extracted frames.\n",
        "        lukas_kanade_dir (str): Directory to save optical flow images.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Looking for extracted frames in folder: {extracted_frames_dir}\")\n",
        "\n",
        "    for root, dirs, files in os.walk(extracted_frames_dir):\n",
        "        for subfolder in subfolders:\n",
        "            if subfolder in root:\n",
        "                lukas_kanade_subfolder = os.path.join(lukas_kanade_dir, subfolder)\n",
        "                video_frames_dir = root  # Current video frames folder\n",
        "                logging.info(f\"Processing frames in {video_frames_dir} for Lucas-Kanade optical flow.\")\n",
        "                apply_lukas_kanade_to_frames(video_frames_dir, lukas_kanade_subfolder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(\"Starting Lucas-Kanade optical flow processing...\")\n",
        "    process_all_videos_for_lukas_kanade(extracted_frames_dir, lukas_kanade_dir)\n",
        "    logging.info(\"Lucas-Kanade optical flow processing completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ssp-RBIsm3Xv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Input,\n",
        "    Concatenate,\n",
        "    GlobalAveragePooling2D,\n",
        "    Conv2D,\n",
        "    MaxPooling2D\n",
        ")\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D_QQVJ4Km3Up"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "extracted_frames_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/extracted_frames\"\n",
        "output_csv = \"/content/drive/My Drive/pour_la_hackathon/MineAI/site_data.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Immwf8xoU8go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abb04f7-26fc-49a9-f916-6bc0e03e10db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Site  Fragment Size Distribution  Visual Fragmentation  \\\n",
            "0   352_108                           1                     1   \n",
            "1   352_121                           3                     4   \n",
            "2   328_109                           4                     4   \n",
            "3   340_102                           3                     3   \n",
            "4   352_103                           3                     3   \n",
            "5   352_131                           4                     4   \n",
            "6   352_132                           1                     3   \n",
            "7   352_137                           4                     4   \n",
            "8   352_138                           2                     2   \n",
            "9   352_312                           3                     3   \n",
            "10  364_105                           3                     3   \n",
            "11  364_303                           3                     3   \n",
            "\n",
            "    Boulders (>1 m)  Fines (<10 mm)  Most Blasts  \\\n",
            "0                 1               3            2   \n",
            "1                 3               3            0   \n",
            "2                 4               3            0   \n",
            "3                 4               4            4   \n",
            "4                 3               2            0   \n",
            "5                 4               4            0   \n",
            "6                 1               4            0   \n",
            "7                 4               4            0   \n",
            "8                 0               0            0   \n",
            "9                 3               3            0   \n",
            "10                3               3            0   \n",
            "11                3               3            0   \n",
            "\n",
            "    For Development and Pinoeering blast  \\\n",
            "0                                      0   \n",
            "1                                      1   \n",
            "2                                      4   \n",
            "3                                      0   \n",
            "4                                      2   \n",
            "5                                      4   \n",
            "6                                      4   \n",
            "7                                      4   \n",
            "8                                      3   \n",
            "9                                      2   \n",
            "10                                     4   \n",
            "11                                     3   \n",
            "\n",
            "    Digability (Ease of Excavation) - Simple Method  Muckpile Height  \\\n",
            "0                                                 0                3   \n",
            "1                                                 0                4   \n",
            "2                                                 0                3   \n",
            "3                                                 0                3   \n",
            "4                                                 3                0   \n",
            "5                                                 3                0   \n",
            "6                                                 2                0   \n",
            "7                                                 4                0   \n",
            "8                                                 2                0   \n",
            "9                                                 4                0   \n",
            "10                                                4                0   \n",
            "11                                                3                0   \n",
            "\n",
            "    Swell Factor  ...  Muckpile Throw  Misfires/Blowouts  Swell and Spread  \\\n",
            "0              2  ...               1                  1                 3   \n",
            "1              4  ...               4                  2                 1   \n",
            "2              2  ...               3                  3                 2   \n",
            "3              4  ...               3                  2                 4   \n",
            "4              0  ...               1                  2                 2   \n",
            "5              0  ...               4                  4                 3   \n",
            "6              0  ...               4                  1                 2   \n",
            "7              0  ...               4                  3                 4   \n",
            "8              0  ...               3                  3                 2   \n",
            "9              0  ...               3                  3                 2   \n",
            "10             0  ...               3                  3                 3   \n",
            "11             0  ...               2                  2                 2   \n",
            "\n",
            "    Fragmentation Distribution.1  Muckpile Shape.1  Misfires/Blowouts.1  \\\n",
            "0                              1                 4                    1   \n",
            "1                              3                 1                    2   \n",
            "2                              4                 4                    3   \n",
            "3                              4                 4                    2   \n",
            "4                              3                 0                    2   \n",
            "5                              4                 3                    4   \n",
            "6                              1                 2                    1   \n",
            "7                              4                 4                    4   \n",
            "8                              2                 2                    3   \n",
            "9                              2                 2                    3   \n",
            "10                             4                 4                    3   \n",
            "11                             3                 4                    2   \n",
            "\n",
            "    Confinement and Ejection (Stemming Quality)  \\\n",
            "0                                             1   \n",
            "1                                             2   \n",
            "2                                             2   \n",
            "3                                             2   \n",
            "4                                             2   \n",
            "5                                             4   \n",
            "6                                             2   \n",
            "7                                             4   \n",
            "8                                             3   \n",
            "9                                             3   \n",
            "10                                            3   \n",
            "11                                            2   \n",
            "\n",
            "    (Vibration Monitor data available)Fish Spawning season - Yes  \\\n",
            "0                                                   0              \n",
            "1                                                   0              \n",
            "2                                                   0              \n",
            "3                                                   0              \n",
            "4                                                   0              \n",
            "5                                                   0              \n",
            "6                                                   0              \n",
            "7                                                   0              \n",
            "8                                                   0              \n",
            "9                                                   0              \n",
            "10                                                  0              \n",
            "11                                                  0              \n",
            "\n",
            "    (Vibration Monitor data available) Fish Spawning season - No  \\\n",
            "0                                                   0              \n",
            "1                                                   0              \n",
            "2                                                   0              \n",
            "3                                                   0              \n",
            "4                                                   0              \n",
            "5                                                   0              \n",
            "6                                                   0              \n",
            "7                                                   0              \n",
            "8                                                   0              \n",
            "9                                                   0              \n",
            "10                                                  0              \n",
            "11                                                  0              \n",
            "\n",
            "    Vibration Monitor Data not available  \n",
            "0                                      1  \n",
            "1                                      2  \n",
            "2                                      2  \n",
            "3                                      2  \n",
            "4                                      2  \n",
            "5                                      4  \n",
            "6                                      3  \n",
            "7                                      3  \n",
            "8                                      2  \n",
            "9                                      2  \n",
            "10                                     3  \n",
            "11                                     4  \n",
            "\n",
            "[12 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "# Subfolders (blast sites)\n",
        "subfolders = ['328_109', '340_102', '352_103', '352_108', '352_137',\n",
        "              '352_132', '352_131', '352_121', '364_303', '364_105',\n",
        "              '352_312', '352_138']\n",
        "\n",
        "# Load CSV data\n",
        "csv_data = pd.read_csv(output_csv)\n",
        "print(csv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bwjs2CYTU_UY"
      },
      "outputs": [],
      "source": [
        "# Prepare data and labels\n",
        "image_features = []\n",
        "labels = []\n",
        "\n",
        "# Image preprocessing parameters\n",
        "IMG_SIZE = (128, 128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    \"\"\"Read and preprocess a single image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_resized = cv2.resize(img, IMG_SIZE)  # Resize to IMG_SIZE\n",
        "    img_normalized = img_resized / 255.0  # Normalize pixel values\n",
        "    return img_normalized\n",
        "\n",
        "# Process each subfolder\n",
        "for subfolder in subfolders:\n",
        "    subfolder_path = os.path.join(extracted_frames_dir, subfolder)\n",
        "    # Check for corresponding data in the CSV\n",
        "    site_data = csv_data[csv_data[\"Site\"] == subfolder]\n",
        "    if site_data.empty:\n",
        "        print(f\"Warning: No CSV data found for {subfolder}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Get the label (parameter values) for this site\n",
        "    site_label = site_data.iloc[0, 1:].values.astype(np.float32)\n",
        "\n",
        "    # List all image files in the subfolder\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "        # Preprocess image\n",
        "        img_feature = preprocess_image(image_path)\n",
        "        image_features.append(img_feature)\n",
        "        labels.append(site_label)\n"
      ],
      "metadata": {
        "id": "P2qxQE9tmRVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VLas1zgEm3Ir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "053dbc72-1a2d-40ad-bc9a-f97ef19331bf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0c03afe50526>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split data into training and testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(image_features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pcVXoS7Dm3F8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "67e496ed-1349-4f22-fbf9-b6323f159277"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'IMG_SIZE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-5954b5fd44b8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build the CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model = Sequential([\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'IMG_SIZE' is not defined"
          ]
        }
      ],
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_train.shape[1], activation='linear')  # Output layer with the number of features\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kev8BW39m3Cz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "72efe0f5-4cee-403d-eafa-c254ef13b69a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1d4f85723593>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mae'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=['mae'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)\n",
        "\n",
        "# Save the model\n",
        "model_save_path = \"/content/drive/My Drive/pour_la_hackathon/MineAI/blast_analysis_model.h5\"\n",
        "\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IqRAhyOIm2_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b179dd53-2790-4604-cc12-fc80390f2770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
            "Predicted features for the new blast: [ 1.2671866e+00  1.3310432e+00  1.2286829e+00  1.2926776e+00\n",
            "  4.1534114e-01  1.1241829e+00  8.8118470e-01  7.5981587e-01\n",
            "  7.2499776e-01  7.7581787e-01  6.7437994e-01  1.0569496e+00\n",
            "  1.1419871e+00  1.2689705e+00  1.1096172e+00  1.1475892e+00\n",
            "  1.2822990e+00  1.1889697e+00  1.1518514e+00  1.1546254e+00\n",
            " -6.9666521e-12 -1.7701760e-12  1.1301622e+00]\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive/My Drive/pour_la_hackathon/MineAI/blast_analysis_model.h5\"\n",
        "model_save_path = \"/content/drive/My Drive/pour_la_hackathon/MineAI/blast_analysis_model.h5\"\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Read and preprocess a single image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img_resized = cv2.resize(img, IMG_SIZE)  # Resize to IMG_SIZE\n",
        "    img_normalized = img_resized / 255.0  # Normalize pixel values\n",
        "    return img_normalized\n",
        "\n",
        "# Prediction function for a new blast\n",
        "def predict_new_blast(model_path, new_frames_dir):\n",
        "    \"\"\"Predict features for a new set of frames.\"\"\"\n",
        "    # Load the trained model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Process new frames\n",
        "    new_features = []\n",
        "    for image_file in os.listdir(new_frames_dir):\n",
        "        image_path = os.path.join(new_frames_dir, image_file)\n",
        "        img_feature = preprocess_image(image_path)\n",
        "        new_features.append(img_feature)\n",
        "\n",
        "    # Convert to numpy array and predict\n",
        "    new_features = np.array(new_features)\n",
        "    predictions = model.predict(new_features)\n",
        "    # Aggregate predictions (mean over all frames)\n",
        "    aggregated_prediction = predictions.mean(axis=0)\n",
        "    return aggregated_prediction\n",
        "\n",
        "# Example usage of prediction function\n",
        "new_frames_dir = \"/content/drive/My Drive/pour_la_hackathon/MineAI/unknown_blast_frames\"\n",
        "predicted_features = predict_new_blast(model_save_path, new_frames_dir)\n",
        "print(\"Predicted features for the new blast:\", predicted_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-djdAwlm29K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwyC_TX_m26N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN0lYS5Jm23W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZyyXP6dm20Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAwma_Oym2xR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StlMUwjqm2uO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zzZROC-m2q5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAtCezn_m2nt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iogHMe8Om2k2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1GxQ87YJ-fnsrTiabGiPOQ7ocT-MTx2oE",
      "authorship_tag": "ABX9TyMUdjG52zpefDMLvx33XvV0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}